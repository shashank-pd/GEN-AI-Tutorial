{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GPU memory growth to avoid memory allocation issues\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the discriminator model\n",
    "def define_discriminator(in_shape=(32,32,3)):\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3,3), padding='same', input_shape=in_shape),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Conv2D(128, (3,3), strides=(2,2), padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Conv2D(128, (3,3), strides=(2,2), padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Flatten(),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "        # Compile the discriminator with binary cross-entropy loss\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator model\n",
    "def define_generator(latent_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128 * 8 * 8, input_dim=latent_dim),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Reshape((8, 8, 128)),\n",
    "        Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Conv2D(3, (3,3), activation='tanh', padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAN by combining generator and discriminator\n",
    "def define_gan(g_model, d_model):\n",
    "    d_model.trainable = False  # Freeze discriminator during GAN training\n",
    "    model = Sequential([g_model, d_model])\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset and preprocess it\n",
    "def load_real_samples():\n",
    "    (trainX, _), (_, _) = load_data()\n",
    "    X = trainX.astype('float32')\n",
    "    X = (X - 127.5) / 127.5  # Normalize images to range [-1,1]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select real images from the dataset\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = np.ones((n_samples, 1))  # Label real images as 1\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random latent points for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    return np.random.randn(n_samples, latent_dim)\n",
    "\n",
    "# Generate fake images using the generator\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = g_model.predict(x_input)\n",
    "    y = np.zeros((n_samples, 1))  # Label fake images as 0\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save generated images at each epoch\n",
    "def save_plot(examples, epoch, n=7):\n",
    "    examples = (examples + 1) / 2.0  # Rescale to [0,1] range\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(examples[i])\n",
    "    filename = f'generated_plot_e{epoch+1:03d}.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the GAN\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=30, n_batch=128):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            # Train discriminator on real images\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
    "            \n",
    "            # Train discriminator on fake images\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
    "            \n",
    "            # Train generator (via GAN model)\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = np.ones((n_batch, 1))  # Labels flipped to 1 to trick the discriminator\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            \n",
    "            print(f'>{i+1}, {j+1}/{bat_per_epo}, d1={d_loss1:.3f}, d2={d_loss2:.3f} g={g_loss:.3f}')\n",
    "        \n",
    "        # Generate and save images at the end of each epoch\n",
    "        X_fake, _ = generate_fake_samples(g_model, latent_dim, 49)\n",
    "        save_plot(X_fake, i)\n",
    "        print(f'Saved generated images for epoch {i+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training process with GPU acceleration\n",
    "with tf.device('/GPU:0'):\n",
    "    latent_dim = 100  # Size of the latent space\n",
    "    d_model = define_discriminator()\n",
    "    g_model = define_generator(latent_dim)\n",
    "    gan_model = define_gan(g_model, d_model)\n",
    "    dataset = load_real_samples()\n",
    "    train(g_model, d_model, gan_model, dataset, latent_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
