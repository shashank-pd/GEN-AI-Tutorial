{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 20\n",
    "batch_size = 256\n",
    "learning_rate = 5e-4\n",
    "epochs = 50\n",
    "\n",
    "# Data Loading\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# VAE Model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 400),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(400, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(400, latent_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 28 * 28),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu, logvar = self.fc_mu(x), self.fc_logvar(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar\n",
    "\n",
    "# Loss Function\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    reconstruction_loss = F.binary_cross_entropy(recon_x, x.view(-1, 28 * 28), reduction='sum')\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return reconstruction_loss + kl_divergence\n",
    "\n",
    "# Training Loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VAE(latent_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Plot Loss Curve\n",
    "plt.plot(range(1, epochs + 1), train_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()\n",
    "\n",
    "# Reconstruction and Visualization\n",
    "def visualize_reconstructions(model, data_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data, _ = next(iter(data_loader))\n",
    "        data = data.to(device)\n",
    "        recon_data, _, _ = model(data)\n",
    "        data, recon_data = data.cpu(), recon_data.cpu()\n",
    "        fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "        for i in range(10):\n",
    "            axes[0, i].imshow(data[i].reshape(28, 28), cmap='gray')\n",
    "            axes[1, i].imshow(recon_data[i].reshape(28, 28), cmap='gray')\n",
    "            axes[0, i].axis('off')\n",
    "            axes[1, i].axis('off')\n",
    "        plt.show()\n",
    "\n",
    "visualize_reconstructions(model, test_loader)\n",
    "\n",
    "# Latent Space Visualization\n",
    "def visualize_latent_space(model, data_loader):\n",
    "    model.eval()\n",
    "    latents, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, label in data_loader:\n",
    "            data = data.to(device)\n",
    "            _, mu, _ = model(data)\n",
    "            latents.append(mu.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "    latents, labels = np.vstack(latents), np.hstack(labels)\n",
    "    tsne = TSNE(n_components=2)\n",
    "    latents_2d = tsne.fit_transform(latents)\n",
    "    plt.scatter(latents_2d[:, 0], latents_2d[:, 1], c=labels, cmap='jet', alpha=0.5)\n",
    "    plt.colorbar()\n",
    "    plt.title('Latent Space Visualization')\n",
    "    plt.show()\n",
    "\n",
    "visualize_latent_space(model, test_loader)\n",
    "\n",
    "# Generate New Images\n",
    "def generate_images(model, num_images=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_images, latent_dim).to(device)\n",
    "        samples = model.decoder(z).cpu()\n",
    "        fig, axes = plt.subplots(1, num_images, figsize=(10, 1))\n",
    "        for i in range(num_images):\n",
    "            axes[i].imshow(samples[i].reshape(28, 28), cmap='gray')\n",
    "            axes[i].axis('off')\n",
    "        plt.show()\n",
    "\n",
    "generate_images(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
